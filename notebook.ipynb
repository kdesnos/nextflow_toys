{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nextflow optimizer notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current objective of this notebook is to:\n",
    "1. Load execution trace of a Nextflow workflow.\n",
    "2. Extract timing information of the different tasks executed.\n",
    "3. (Optionnaly) Visualize the extracted information, similarly to what is done in nextflow reports\n",
    "4. Generate Nextflow config file overriding the process time limit with the worst-case execution time observed.\n",
    "\n",
    "In future version, it might be useful to maintain a database of process runtimes to better understand how this runtime evolves depending on its parameterization, or depending on the node used to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Path to the report and dag files.\n",
    "#nf_report_path = Path(\"C:/Users/kdesnos/Desktop/Sandbox/pipelines/CELEBI_20250214\",\"karol_210912_ult_2025-02-21_15_23_50\")\n",
    "nf_report_path = Path(\"C:/Users/kdesnos/Desktop/Sandbox/pipelines/\",\"execution_2025-02-14_10-15-33\")\n",
    "# karol_210912_ult_2025-02-14_12_57_21\n",
    "\n",
    "# Output config file\n",
    "output_config_file = Path(\"C:/Users/kdesnos/Desktop/Sandbox/pipelines/CELEBI_20250214\",\"karol_210912_ult.config\")\n",
    "\n",
    "# Create the HTML and DAG files\n",
    "html_report = nf_report_path.with_name(nf_report_path.name + \"_report.html\")\n",
    "dag_report = nf_report_path.with_name(nf_report_path.name + \"_dag.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load data from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_trace_from_html as parser\n",
    "\n",
    "trace_df = parser.extract_trace_data(html_report)\n",
    "\n",
    "if trace_df is not None:\n",
    "    print(f\"Extracted {trace_df.shape[0]} process execution traces.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Process dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract process name and path within the workflow as separate columns.\n",
    "trace_df['process_name'] = trace_df['process'].str.split(':').str[-1]\n",
    "trace_df['process_path'] = trace_df['process'].str.split(':').str[:-1].str.join(':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Display useful info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Process execution time box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization as visualizer\n",
    "\n",
    "name_filter = None # Optionnaly a string can be given to the viewer to display only processes containing this string\n",
    "                   # Use None if no filter is wanted\n",
    "\n",
    "visualizer.plot_realtime_boxplot(trace_df, name_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Icicle chart of processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization as visualizer\n",
    "\n",
    "visualizer.plot_icicle_chart(trace_df, include_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Processing times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = trace_df['realtime'].sum()\n",
    "sum_cpu = (trace_df['realtime'] * trace_df['cpus']).sum()\n",
    "\n",
    "print(f'Sum of all process execution time: {sum}')\n",
    "print(f'Sum of all (process exec time)*(nb cpu): {sum_cpu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Average wait time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization as visualizer\n",
    "\n",
    "visualizer.plot_wait_times(trace_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_file_generator as generator\n",
    "\n",
    "generator.generate_nextflow_config(trace_df, output_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_mermaid_graph(dag_report: Path) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Extracts a Mermaid DAG from an HTML file and returns it as a NetworkX graph.\n",
    "\n",
    "    Parameters:\n",
    "    - dag_report (Path): The path to the HTML file containing the Mermaid DAG.\n",
    "\n",
    "    Returns:\n",
    "    - nx.DiGraph: The NetworkX directed graph representing the DAG.\n",
    "    \"\"\"\n",
    "    # Read the HTML file\n",
    "    with open(dag_report, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Regular expression to extract the Mermaid graph definition\n",
    "    mermaid_pattern = re.compile(r'<pre class=\"mermaid\" style=\"text-align: center;\">(.*?)</pre>', re.DOTALL)\n",
    "    mermaid_match = mermaid_pattern.search(html_content)\n",
    "\n",
    "    if not mermaid_match:\n",
    "        raise ValueError(\"Mermaid graph definition not found in the HTML file.\")\n",
    "\n",
    "    mermaid_graph = mermaid_match.group(1).strip()\n",
    "\n",
    "    # Regular expressions to extract nodes, edges, and subgraphs\n",
    "    node_pattern = re.compile(r'(\\w+)[\\[|\\()|\\\"]+(.*?)[\\\"|\\]|\\)]+')\n",
    "    edge_pattern = re.compile(r'(\\w+) --> (\\w+)')\n",
    "    subgraph_pattern = re.compile(r'subgraph\\s+(\\w+|\".*?\")', re.DOTALL)\n",
    "\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Extract nodes and their names\n",
    "    nodes = node_pattern.findall(mermaid_graph)\n",
    "    node_names = {node: name for node, name in nodes}\n",
    "\n",
    "    for node, name in nodes:\n",
    "        G.add_node(node, name=name)\n",
    "\n",
    "    # Extract edges\n",
    "    edges = edge_pattern.findall(mermaid_graph)\n",
    "    for source, target in edges:\n",
    "        G.add_edge(source, target)\n",
    "\n",
    "    # Extract subgraphs\n",
    "    subgraph_lines = mermaid_graph.splitlines()\n",
    "    subgraph_name = None\n",
    "    in_subgraph = False\n",
    "    anonymous_subgraph_count = 0\n",
    "\n",
    "    for line in subgraph_lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('subgraph'):\n",
    "            if in_subgraph:\n",
    "                # Process the previous subgraph\n",
    "                subgraph_name = None\n",
    "            subgraph_name_match = subgraph_pattern.match(line)\n",
    "            if subgraph_name_match:\n",
    "                subgraph_name = subgraph_name_match.group(1).strip('\"')\n",
    "                if subgraph_name == \" \":\n",
    "                    subgraph_name = f'unnamed_{anonymous_subgraph_count}'\n",
    "                    anonymous_subgraph_count += 1\n",
    "            in_subgraph = True\n",
    "        elif line == 'end' and in_subgraph:\n",
    "            in_subgraph = False\n",
    "        elif in_subgraph:\n",
    "            node_match = node_pattern.match(line)\n",
    "            if node_match:\n",
    "                node, name = node_match.groups()\n",
    "                G.add_node(node, name=name, subgraph=subgraph_name)\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "# Example usage\n",
    "dag = extract_mermaid_graph(dag_report)\n",
    "\n",
    "# Print nodes and edges in a simpler format\n",
    "print(f\"{dag.number_of_nodes()} Nodes:\", dag.nodes(data=True))\n",
    "print(f\"{dag.number_of_edges()} Edges:\", dag.edges())\n",
    "\n",
    "lay = enumerate(nx.topological_generations(dag))\n",
    "for layer, nodes in lay:\n",
    "    for node in nodes:\n",
    "        dag.nodes[node][\"layer\"] = layer\n",
    "\n",
    "nx.draw(dag, pos = nx.multipartite_layout(dag, subset_key=\"layer\"), with_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
