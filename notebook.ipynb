{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nextflow optimizer notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current objective of this notebook is to:\n",
    "1. Load execution trace of a Nextflow workflow.\n",
    "2. Extract timing information of the different tasks executed.\n",
    "3. (Optionnaly) Visualize the extracted information, similarly to what is done in nextflow reports\n",
    "4. Generate Nextflow config file overriding the process time limit with the worst-case execution time observed.\n",
    "\n",
    "In future version, it might be useful to maintain a database of process runtimes to better understand how this runtime evolves depending on its parameterization, or depending on the node used to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from nf_trace_db_manager import NextflowTraceDBManager\n",
    "\n",
    "# Path to the report and dag files.\n",
    "# nf_report_path = Path(\"./dat/250515_241226_CELEBI/\",\"karol_241226_ult_2025-05-15_13_41_42\")\n",
    "nf_report_path = Path(\"./dat/250625_250313_CELEBI_wConfig/\",\"karol_250313_2025-06-25_15_08_44\")\n",
    "#nf_report_path = Path(\"C:/Users/kdesnos/Desktop/Sandbox/pipelines/\",\"execution_2025-02-14_10-15-33\")\n",
    "\n",
    "# Create the HTML and DAG files\n",
    "html_report = nf_report_path.with_name(nf_report_path.name + \"_report.html\")\n",
    "dag_report = nf_report_path.with_name(nf_report_path.name + \"_dag.html\")\n",
    "output_config_file = nf_report_path.with_name(nf_report_path.name + \"_config.config\")\n",
    "log_report = nf_report_path.with_name(nf_report_path.name + \"_log.log\")\n",
    "\n",
    "# DB Manager \n",
    "db_manager = NextflowTraceDBManager(\"./dat/nf_trace_db.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load data from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_trace_from_html as parser\n",
    "\n",
    "trace_df = parser.extract_trace_data(html_report)\n",
    "\n",
    "if trace_df is not None:\n",
    "    print(f\"Extracted {trace_df.shape[0]} process execution traces.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Display useful info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Process execution time box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization as visualizer\n",
    "\n",
    "name_filter = None # Optionnaly a string can be given to the viewer to display only processes containing this string\n",
    "                   # Use None if no filter is wanted\n",
    "\n",
    "visualizer.plot_realtime_boxplot(trace_df, name_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Icicle chart of processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization as visualizer\n",
    "\n",
    "visualizer.plot_icicle_chart(trace_df, include_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Processing times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = trace_df['realtime'].sum()\n",
    "sum_cpu = (trace_df['realtime'] * trace_df['cpus']).sum()\n",
    "\n",
    "print(f'Sum of all process execution time: {sum}')\n",
    "print(f'Sum of all (process exec time)*(nb cpu): {sum_cpu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Average wait time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization as visualizer\n",
    "\n",
    "visualizer.plot_wait_times(trace_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Memory Utilization Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate memory utilization ratio (peak_rss / memory)\n",
    "# Filter out rows where memory is zero or NaN to avoid division by zero\n",
    "valid_memory_df = trace_df[(trace_df['memory'] > 0) & (~trace_df['memory'].isna())]\n",
    "\n",
    "# Calculate the ratio for each process execution\n",
    "memory_ratio = valid_memory_df['peak_rss'] / valid_memory_df['memory']\n",
    "\n",
    "# Calculate the average ratio\n",
    "avg_memory_ratio = memory_ratio.mean()\n",
    "\n",
    "print(f\"Average memory utilization ratio (peak_rss / memory): {avg_memory_ratio:.2%}\")\n",
    "print(f\"Number of processes with valid memory allocation: {len(valid_memory_df)} out of {len(trace_df)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Time Utilization Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where time is NaN or realtime is non-positive\n",
    "from pandas import Timedelta\n",
    "\n",
    "# Define the 60-second buffer as a Timedelta object\n",
    "buffer_time = Timedelta(seconds=60)\n",
    "\n",
    "valid_time_df = trace_df[(~trace_df['time'].isna()) & (trace_df['realtime'] > Timedelta(0))]\n",
    "\n",
    "# Calculate allocated time utilization ratio (realtime / time)\n",
    "time_ratio = valid_time_df['realtime'] / valid_time_df['time']\n",
    "avg_time_ratio = time_ratio.mean()\n",
    "\n",
    "# Calculate predicted time ratio (realtime / (time - 60sec))\n",
    "# This accounts for the 60-second buffer added to time limits\n",
    "predicted_time_ratio = valid_time_df['realtime'] / (valid_time_df['time'] - buffer_time)\n",
    "avg_predicted_ratio = predicted_time_ratio.mean()\n",
    "\n",
    "# Count how many times realtime < (time - 60sec)\n",
    "count_under_predicted = (valid_time_df['realtime'] < (valid_time_df['time'] - buffer_time)).sum()\n",
    "percentage_under_predicted = count_under_predicted / len(valid_time_df) * 100 if len(valid_time_df) > 0 else 0\n",
    "\n",
    "print(f\"Average allocated time utilization ratio (realtime / time): {avg_time_ratio:.2%}\")\n",
    "print(f\"Average predicted time ratio (realtime / (time - buffer)): {avg_predicted_ratio:.2%}\")\n",
    "print(f\"Number of processes with realtime < (time - buffer): {count_under_predicted} out of {len(valid_time_df)} ({percentage_under_predicted:.2f}%)\")\n",
    "print(f\"Number of processes with valid time allocation: {len(valid_time_df)} out of {len(trace_df)}\")\n",
    "\n",
    "# Visualization of time utilization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a boxplot to show distribution of time utilization ratios\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot([time_ratio, predicted_time_ratio], labels=['Allocated Ratio', 'Predicted Ratio'])\n",
    "plt.ylabel('Ratio Value')\n",
    "plt.title('Distribution of Time Utilization Ratios')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Create a histogram of time utilization ratio\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(time_ratio, bins=20, alpha=0.7, color='skyblue', edgecolor='black', label='Allocated')\n",
    "plt.hist(predicted_time_ratio, bins=20, alpha=0.5, color='orange', edgecolor='black', label='Predicted')\n",
    "plt.axvline(avg_time_ratio, color='blue', linestyle='dashed', linewidth=2, label=f'Avg Allocated: {avg_time_ratio:.2%}')\n",
    "plt.axvline(avg_predicted_ratio, color='red', linestyle='dashed', linewidth=2, label=f'Avg Predicted: {avg_predicted_ratio:.2%}')\n",
    "plt.xlabel('Time Utilization Ratio')\n",
    "plt.ylabel('Number of Processes')\n",
    "plt.title('Distribution of Time Utilization Ratios')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_file_generator as generator\n",
    "\n",
    "generator.generate_nextflow_config_from_trace(trace_df, output_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Import from Mermaid DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import import_dag_from_mermaid_html as dag_importer\n",
    "\n",
    "# Example usage\n",
    "dag = dag_importer.extract_mermaid_graph(dag_report)\n",
    "\n",
    "# Check if the graph is a DAG\n",
    "if not nx.is_directed_acyclic_graph(dag):\n",
    "    raise ValueError(\"The extracted graph is not a DAG.\")\n",
    "\n",
    "# Print nodes and edges in a simpler format\n",
    "print(f\"{dag.number_of_nodes()} Nodes:\", dag.nodes(data=True))\n",
    "print(f\"{dag.number_of_edges()} Edges:\", dag.edges(data=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Update with trace info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_importer.add_execution_counts_to_graph(dag, trace_df)\n",
    "\n",
    "print(f\"{dag.number_of_nodes()} Nodes:\", dag.nodes(data=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Export as DOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import export_dag_to_dot as dag_exporter\n",
    "\n",
    "dag_exporter.export_to_dot(dag, nf_report_path.with_name(nf_report_path.name + \"_dag.dot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Export as PiSDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from export_dag_to_pisdf import PreesmExporter\n",
    "import export_dag_to_dot as dag_exporter\n",
    "\n",
    "preesm_exporter = PreesmExporter(nf_report_path.parent / \"nextflow_toy\", db_manager, html_report, dag_report)\n",
    "\n",
    "dag_exporter.export_to_dot(preesm_exporter.graph, nf_report_path.with_name(nf_report_path.name + \"_dag.dot\"))\n",
    "preesm_exporter.export_preesm_project(log_report, {1: 4, 16: 2, 32: 4})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
